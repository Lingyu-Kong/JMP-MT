{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Type checking the following modules: ('jmppeft',)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script> (()=>{ if (customElements.get('treescope-container') === undefined) { class TreescopeContainer extends HTMLElement { constructor() { super(); this.attachShadow({mode: \"open\"}); this.defns = {}; this.state = {}; } } customElements.define(\"treescope-container\", TreescopeContainer); } if (customElements.get('treescope-run-here') === undefined) { class RunHere extends HTMLElement { constructor() { super() } connectedCallback() { const run = child => { const fn = new Function(child.textContent); child.textContent = \"\"; fn.call(this); this.remove(); }; const child = this.querySelector(\"script\"); if (child) { run(child); } else { new MutationObserver(()=>{ run(this.querySelector(\"script\")); }).observe(this, {childList: true}); } } } customElements.define(\"treescope-run-here\", RunHere); } })(); </script> <treescope-container class=\"treescope_out_d5880536f01240c08cfae1467852c484\" ></treescope-container> <treescope-run-here><script type=\"application/octet-stream\"> const root = ( Array.from(document.getElementsByClassName( \"treescope_out_d5880536f01240c08cfae1467852c484\")) .filter((elt) => !elt.dataset.setup) )[0]; root.dataset.setup = 1; const msg = document.createElement(\"span\"); msg.style = \"color: #cccccc; font-family: monospace;\"; msg.textContent = \"(Loading...)\"; root.state.loadingMsg = msg; root.shadowRoot.appendChild(msg); root.state.chain = new Promise((resolve, reject) => { const observer = new IntersectionObserver((entries) => { for (const entry of entries) { if (entry.isIntersecting) { resolve(); observer.disconnect(); return; } } }, {rootMargin: \"1000px\"}); window.setTimeout(() => { observer.observe(root); }, 0); }); root.state.deferring = false; const _insertNode = (node) => { for (let oldScript of node.querySelectorAll(\"script\")) { let newScript = document.createElement(\"script\"); newScript.type = oldScript.type; newScript.textContent = oldScript.textContent; oldScript.parentNode.replaceChild(newScript, oldScript); } if (root.state.loadingMsg) { root.state.loadingMsg.remove(); root.state.loadingMsg = null; } root.shadowRoot.appendChild(node); }; root.defns.insertContent = ((contentNode, compressed) => { if (compressed) { root.state.deferring = true; } if (root.state.deferring) { root.state.chain = (async () => { await root.state.chain; if (compressed) { const encoded = contentNode.textContent; const blob = new Blob([ Uint8Array.from(atob(encoded), (m) => m.codePointAt(0)) ]); const reader = blob.stream().pipeThrough( new DecompressionStream(\"deflate\") ).pipeThrough( new TextDecoderStream(\"utf-8\") ).getReader(); const parts = []; while (true) { const step = await reader.read(); if (step.done) { break; } parts.push(step.value); } const tpl = document.createElement('template'); tpl.innerHTML = parts.join(\"\"); _insertNode(tpl.content); } else { _insertNode(contentNode.content); } })(); } else { _insertNode(contentNode.content); } }); </script></treescope-run-here><div style=\"display:none\"> <script type=\"application/octet-stream\" >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</script> <treescope-run-here><script type=\"application/octet-stream\"> const root = ( Array.from(document.getElementsByClassName( \"treescope_out_d5880536f01240c08cfae1467852c484\")) .filter((elt) => !elt.dataset['step0']) )[0]; root.dataset['step0'] = 1; root.defns.insertContent( this.parentNode.querySelector('script[type=\"application/octet-stream\"]'), true ); this.parentNode.remove(); </script></treescope-run-here> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script> (()=>{ if (customElements.get('treescope-container') === undefined) { class TreescopeContainer extends HTMLElement { constructor() { super(); this.attachShadow({mode: \"open\"}); this.defns = {}; this.state = {}; } } customElements.define(\"treescope-container\", TreescopeContainer); } if (customElements.get('treescope-run-here') === undefined) { class RunHere extends HTMLElement { constructor() { super() } connectedCallback() { const run = child => { const fn = new Function(child.textContent); child.textContent = \"\"; fn.call(this); this.remove(); }; const child = this.querySelector(\"script\"); if (child) { run(child); } else { new MutationObserver(()=>{ run(this.querySelector(\"script\")); }).observe(this, {childList: true}); } } } customElements.define(\"treescope-run-here\", RunHere); } })(); </script> <treescope-container class=\"treescope_out_c0532644867c4ec2b1ca46be5b556053\" ></treescope-container> <treescope-run-here><script type=\"application/octet-stream\"> const root = ( Array.from(document.getElementsByClassName( \"treescope_out_c0532644867c4ec2b1ca46be5b556053\")) .filter((elt) => !elt.dataset.setup) )[0]; root.dataset.setup = 1; const msg = document.createElement(\"span\"); msg.style = \"color: #cccccc; font-family: monospace;\"; msg.textContent = \"(Loading...)\"; root.state.loadingMsg = msg; root.shadowRoot.appendChild(msg); root.state.chain = new Promise((resolve, reject) => { const observer = new IntersectionObserver((entries) => { for (const entry of entries) { if (entry.isIntersecting) { resolve(); observer.disconnect(); return; } } }, {rootMargin: \"1000px\"}); window.setTimeout(() => { observer.observe(root); }, 0); }); root.state.deferring = false; const _insertNode = (node) => { for (let oldScript of node.querySelectorAll(\"script\")) { let newScript = document.createElement(\"script\"); newScript.type = oldScript.type; newScript.textContent = oldScript.textContent; oldScript.parentNode.replaceChild(newScript, oldScript); } if (root.state.loadingMsg) { root.state.loadingMsg.remove(); root.state.loadingMsg = null; } root.shadowRoot.appendChild(node); }; root.defns.insertContent = ((contentNode, compressed) => { if (compressed) { root.state.deferring = true; } if (root.state.deferring) { root.state.chain = (async () => { await root.state.chain; if (compressed) { const encoded = contentNode.textContent; const blob = new Blob([ Uint8Array.from(atob(encoded), (m) => m.codePointAt(0)) ]); const reader = blob.stream().pipeThrough( new DecompressionStream(\"deflate\") ).pipeThrough( new TextDecoderStream(\"utf-8\") ).getReader(); const parts = []; while (true) { const step = await reader.read(); if (step.done) { break; } parts.push(step.value); } const tpl = document.createElement('template'); tpl.innerHTML = parts.join(\"\"); _insertNode(tpl.content); } else { _insertNode(contentNode.content); } })(); } else { _insertNode(contentNode.content); } }); </script></treescope-run-here><div style=\"display:none\"> <script type=\"application/octet-stream\" >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</script> <treescope-run-here><script type=\"application/octet-stream\"> const root = ( Array.from(document.getElementsByClassName( \"treescope_out_c0532644867c4ec2b1ca46be5b556053\")) .filter((elt) => !elt.dataset['step0']) )[0]; root.dataset['step0'] = 1; root.defns.insertContent( this.parentNode.querySelector('script[type=\"application/octet-stream\"]'), true ); this.parentNode.remove(); </script></treescope-run-here> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import nshconfig_extra as CE\n",
    "import nshtrainer as nt\n",
    "import nshutils as nu\n",
    "from jmp.lightning_datamodule import MPTrjAlexOMAT24DataModuleConfig\n",
    "from jmp.lightning_module import Config, TargetsConfig\n",
    "from jmp.nn.energy_head import EnergyTargetConfig\n",
    "from jmp.nn.force_head import ForceTargetConfig\n",
    "from jmp.nn.stress_head import StressTargetConfig\n",
    "\n",
    "env = {\n",
    "    \"HF_HOME\": \"/net/csefiles/coc-fung-cluster/nima/shared/cache/huggingface\",\n",
    "}\n",
    "\n",
    "config = Config.draft()\n",
    "config.pretrained_ckpt = CE.CachedPath(\n",
    "    uri=\"/net/csefiles/coc-fung-cluster/nima/shared/checkpoints/jmp-s.pt\"\n",
    ")\n",
    "config.optimizer = nt.config.AdamWConfig(lr=5.0e-5, weight_decay=0.001)\n",
    "config.lr_scheduler = nt.config.LinearWarmupCosineDecayLRSchedulerConfig(\n",
    "    warmup_duration=nt.config.StepsConfig(value=5000),\n",
    "    warmup_start_lr_factor=0.001,\n",
    "    max_duration=nt.config.StepsConfig(value=500_000),\n",
    "    min_lr_factor=0.1,\n",
    ")\n",
    "config.targets = TargetsConfig(\n",
    "    energy=EnergyTargetConfig(max_atomic_number=120),\n",
    "    force=ForceTargetConfig(),\n",
    "    stress=StressTargetConfig(num_layers=5),\n",
    ")\n",
    "config.trainer.precision = \"16-mixed-auto\"\n",
    "config.trainer.set_float32_matmul_precision = \"medium\"\n",
    "config = config.finalize()\n",
    "nu.display(config)\n",
    "\n",
    "data_config = MPTrjAlexOMAT24DataModuleConfig.draft()\n",
    "data_config.batch_size = 80\n",
    "data_config.num_workers = 8\n",
    "data_config.salex.local_path = Path(\"/storage/nima/salex-ocp/hf/\")\n",
    "data_config.omat24.local_path = Path(\"/storage/nima/omat24/hf/\")\n",
    "data_config.with_linear_reference_(\"mptrj-salex\")\n",
    "data_config = data_config.finalize()\n",
    "nu.display(data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jmp.lightning_datamodule import MPTrjAlexOMAT24DataModule\n",
    "from jmp.lightning_module import Module\n",
    "\n",
    "\n",
    "def run(config: Config, data_config: MPTrjAlexOMAT24DataModuleConfig):\n",
    "    module = Module(config)\n",
    "    datamodule = MPTrjAlexOMAT24DataModule(data_config)\n",
    "    trainer = nt.Trainer(config)\n",
    "    trainer.fit(module, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019260c5d2aa497f97c094c93c576ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unrecognized arguments:  dict_keys(['ln', 'dropout', 'replace_scale_factors_with_ln', 'learnable_rbf', 'learnable_rbf_stds', 'unique_basis_per_layer', 'old_gaussian_implementation', 'edge_dropout'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:Found the following scale factors: [('int_blocks.0.trip_interaction.scale_rbf', 'int_blocks.0.trip_interaction.scale_rbf'), ('int_blocks.0.trip_interaction.scale_cbf_sum', 'int_blocks.0.trip_interaction.scale_cbf_sum'), ('int_blocks.0.quad_interaction.scale_rbf', 'int_blocks.0.quad_interaction.scale_rbf'), ('int_blocks.0.quad_interaction.scale_cbf', 'int_blocks.0.quad_interaction.scale_cbf'), ('int_blocks.0.quad_interaction.scale_sbf_sum', 'int_blocks.0.quad_interaction.scale_sbf_sum'), ('int_blocks.0.atom_edge_interaction.scale_rbf', 'int_blocks.0.atom_edge_interaction.scale_rbf'), ('int_blocks.0.atom_edge_interaction.scale_cbf_sum', 'int_blocks.0.atom_edge_interaction.scale_cbf_sum'), ('int_blocks.0.edge_atom_interaction.scale_rbf', 'int_blocks.0.edge_atom_interaction.scale_rbf'), ('int_blocks.0.edge_atom_interaction.scale_cbf_sum', 'int_blocks.0.edge_atom_interaction.scale_cbf_sum'), ('int_blocks.0.atom_interaction.scale_rbf_sum', 'int_blocks.0.atom_interaction.scale_rbf_sum'), ('int_blocks.0.atom_update.scale_sum', 'int_blocks.0.atom_update.scale_sum'), ('int_blocks.1.trip_interaction.scale_rbf', 'int_blocks.1.trip_interaction.scale_rbf'), ('int_blocks.1.trip_interaction.scale_cbf_sum', 'int_blocks.1.trip_interaction.scale_cbf_sum'), ('int_blocks.1.quad_interaction.scale_rbf', 'int_blocks.1.quad_interaction.scale_rbf'), ('int_blocks.1.quad_interaction.scale_cbf', 'int_blocks.1.quad_interaction.scale_cbf'), ('int_blocks.1.quad_interaction.scale_sbf_sum', 'int_blocks.1.quad_interaction.scale_sbf_sum'), ('int_blocks.1.atom_edge_interaction.scale_rbf', 'int_blocks.1.atom_edge_interaction.scale_rbf'), ('int_blocks.1.atom_edge_interaction.scale_cbf_sum', 'int_blocks.1.atom_edge_interaction.scale_cbf_sum'), ('int_blocks.1.edge_atom_interaction.scale_rbf', 'int_blocks.1.edge_atom_interaction.scale_rbf'), ('int_blocks.1.edge_atom_interaction.scale_cbf_sum', 'int_blocks.1.edge_atom_interaction.scale_cbf_sum'), ('int_blocks.1.atom_interaction.scale_rbf_sum', 'int_blocks.1.atom_interaction.scale_rbf_sum'), ('int_blocks.1.atom_update.scale_sum', 'int_blocks.1.atom_update.scale_sum'), ('int_blocks.2.trip_interaction.scale_rbf', 'int_blocks.2.trip_interaction.scale_rbf'), ('int_blocks.2.trip_interaction.scale_cbf_sum', 'int_blocks.2.trip_interaction.scale_cbf_sum'), ('int_blocks.2.quad_interaction.scale_rbf', 'int_blocks.2.quad_interaction.scale_rbf'), ('int_blocks.2.quad_interaction.scale_cbf', 'int_blocks.2.quad_interaction.scale_cbf'), ('int_blocks.2.quad_interaction.scale_sbf_sum', 'int_blocks.2.quad_interaction.scale_sbf_sum'), ('int_blocks.2.atom_edge_interaction.scale_rbf', 'int_blocks.2.atom_edge_interaction.scale_rbf'), ('int_blocks.2.atom_edge_interaction.scale_cbf_sum', 'int_blocks.2.atom_edge_interaction.scale_cbf_sum'), ('int_blocks.2.edge_atom_interaction.scale_rbf', 'int_blocks.2.edge_atom_interaction.scale_rbf'), ('int_blocks.2.edge_atom_interaction.scale_cbf_sum', 'int_blocks.2.edge_atom_interaction.scale_cbf_sum'), ('int_blocks.2.atom_interaction.scale_rbf_sum', 'int_blocks.2.atom_interaction.scale_rbf_sum'), ('int_blocks.2.atom_update.scale_sum', 'int_blocks.2.atom_update.scale_sum'), ('int_blocks.3.trip_interaction.scale_rbf', 'int_blocks.3.trip_interaction.scale_rbf'), ('int_blocks.3.trip_interaction.scale_cbf_sum', 'int_blocks.3.trip_interaction.scale_cbf_sum'), ('int_blocks.3.quad_interaction.scale_rbf', 'int_blocks.3.quad_interaction.scale_rbf'), ('int_blocks.3.quad_interaction.scale_cbf', 'int_blocks.3.quad_interaction.scale_cbf'), ('int_blocks.3.quad_interaction.scale_sbf_sum', 'int_blocks.3.quad_interaction.scale_sbf_sum'), ('int_blocks.3.atom_edge_interaction.scale_rbf', 'int_blocks.3.atom_edge_interaction.scale_rbf'), ('int_blocks.3.atom_edge_interaction.scale_cbf_sum', 'int_blocks.3.atom_edge_interaction.scale_cbf_sum'), ('int_blocks.3.edge_atom_interaction.scale_rbf', 'int_blocks.3.edge_atom_interaction.scale_rbf'), ('int_blocks.3.edge_atom_interaction.scale_cbf_sum', 'int_blocks.3.edge_atom_interaction.scale_cbf_sum'), ('int_blocks.3.atom_interaction.scale_rbf_sum', 'int_blocks.3.atom_interaction.scale_rbf_sum'), ('int_blocks.3.atom_update.scale_sum', 'int_blocks.3.atom_update.scale_sum'), ('out_blocks.0.scale_sum', 'out_blocks.0.scale_sum'), ('out_blocks.0.scale_rbf_F', 'out_blocks.0.scale_rbf_F'), ('out_blocks.1.scale_sum', 'out_blocks.1.scale_sum'), ('out_blocks.1.scale_rbf_F', 'out_blocks.1.scale_rbf_F'), ('out_blocks.2.scale_sum', 'out_blocks.2.scale_sum'), ('out_blocks.2.scale_rbf_F', 'out_blocks.2.scale_rbf_F'), ('out_blocks.3.scale_sum', 'out_blocks.3.scale_sum'), ('out_blocks.3.scale_rbf_F', 'out_blocks.3.scale_rbf_F'), ('out_blocks.4.scale_sum', 'out_blocks.4.scale_sum'), ('out_blocks.4.scale_rbf_F', 'out_blocks.4.scale_rbf_F')].\n",
      "CRITICAL:root:Loaded the following scale factors: ['int_blocks.2.trip_interaction.scale_rbf', 'out_blocks.4.scale_rbf_F', 'int_blocks.1.quad_interaction.scale_sbf_sum', 'int_blocks.3.atom_update.scale_sum', 'int_blocks.2.quad_interaction.scale_cbf', 'int_blocks.1.atom_update.scale_sum', 'int_blocks.2.atom_interaction.scale_rbf_sum', 'int_blocks.0.quad_interaction.scale_sbf_sum', 'out_blocks.0.scale_sum', 'int_blocks.1.quad_interaction.scale_cbf', 'int_blocks.2.trip_interaction.scale_cbf_sum', 'int_blocks.3.quad_interaction.scale_rbf', 'int_blocks.3.quad_interaction.scale_sbf_sum', 'int_blocks.1.edge_atom_interaction.scale_cbf_sum', 'out_blocks.3.scale_rbf_F', 'int_blocks.0.atom_edge_interaction.scale_rbf', 'out_blocks.2.scale_sum', 'int_blocks.3.edge_atom_interaction.scale_rbf', 'int_blocks.1.atom_edge_interaction.scale_cbf_sum', 'int_blocks.3.atom_interaction.scale_rbf_sum', 'int_blocks.2.edge_atom_interaction.scale_rbf', 'out_blocks.1.scale_sum', 'int_blocks.3.edge_atom_interaction.scale_cbf_sum', 'int_blocks.2.atom_edge_interaction.scale_rbf', 'out_blocks.0.scale_rbf_F', 'int_blocks.0.trip_interaction.scale_rbf', 'int_blocks.0.edge_atom_interaction.scale_cbf_sum', 'int_blocks.3.atom_edge_interaction.scale_cbf_sum', 'int_blocks.1.trip_interaction.scale_rbf', 'int_blocks.1.quad_interaction.scale_rbf', 'out_blocks.2.scale_rbf_F', 'int_blocks.1.trip_interaction.scale_cbf_sum', 'int_blocks.2.atom_update.scale_sum', 'int_blocks.3.trip_interaction.scale_rbf', 'int_blocks.0.atom_interaction.scale_rbf_sum', 'int_blocks.0.atom_update.scale_sum', 'int_blocks.3.trip_interaction.scale_cbf_sum', 'int_blocks.2.quad_interaction.scale_rbf', 'int_blocks.3.atom_edge_interaction.scale_rbf', 'out_blocks.4.scale_sum', 'int_blocks.1.atom_edge_interaction.scale_rbf', 'int_blocks.0.quad_interaction.scale_cbf', 'int_blocks.1.atom_interaction.scale_rbf_sum', 'int_blocks.2.edge_atom_interaction.scale_cbf_sum', 'out_blocks.3.scale_sum', 'int_blocks.3.quad_interaction.scale_cbf', 'int_blocks.2.quad_interaction.scale_sbf_sum', 'int_blocks.0.quad_interaction.scale_rbf', 'int_blocks.0.edge_atom_interaction.scale_rbf', 'int_blocks.0.atom_edge_interaction.scale_cbf_sum', 'int_blocks.1.edge_atom_interaction.scale_rbf', 'int_blocks.2.atom_edge_interaction.scale_cbf_sum', 'int_blocks.0.trip_interaction.scale_cbf_sum', 'out_blocks.1.scale_rbf_F'].\n",
      "Did not load the following scale factors: [].\n",
      "INFO:jmp.models.gemnet.backbone:Removed the following unnecessary state dict keys from the checkpoint: ['output.out_energy.0.0.weight', 'output.out_energy.0.0.bias', 'output.out_energy.0.2.weight', 'output.out_energy.0.2.bias', 'output.out_energy.0.4.weight', 'output.out_energy.0.4.bias', 'output.out_energy.0.6.weight', 'output.out_energy.0.6.bias', 'output.out_energy.0.8.weight', 'output.out_energy.1.0.weight', 'output.out_energy.1.0.bias', 'output.out_energy.1.2.weight', 'output.out_energy.1.2.bias', 'output.out_energy.1.4.weight', 'output.out_energy.1.4.bias', 'output.out_energy.1.6.weight', 'output.out_energy.1.6.bias', 'output.out_energy.1.8.weight', 'output.out_energy.2.0.weight', 'output.out_energy.2.0.bias', 'output.out_energy.2.2.weight', 'output.out_energy.2.2.bias', 'output.out_energy.2.4.weight', 'output.out_energy.2.4.bias', 'output.out_energy.2.6.weight', 'output.out_energy.2.6.bias', 'output.out_energy.2.8.weight', 'output.out_energy.3.0.weight', 'output.out_energy.3.0.bias', 'output.out_energy.3.2.weight', 'output.out_energy.3.2.bias', 'output.out_energy.3.4.weight', 'output.out_energy.3.4.bias', 'output.out_energy.3.6.weight', 'output.out_energy.3.6.bias', 'output.out_energy.3.8.weight', 'output.out_forces.0.0.weight', 'output.out_forces.0.0.bias', 'output.out_forces.0.2.weight', 'output.out_forces.0.2.bias', 'output.out_forces.0.4.weight', 'output.out_forces.0.4.bias', 'output.out_forces.0.6.weight', 'output.out_forces.0.6.bias', 'output.out_forces.0.8.weight', 'output.out_forces.1.0.weight', 'output.out_forces.1.0.bias', 'output.out_forces.1.2.weight', 'output.out_forces.1.2.bias', 'output.out_forces.1.4.weight', 'output.out_forces.1.4.bias', 'output.out_forces.1.6.weight', 'output.out_forces.1.6.bias', 'output.out_forces.1.8.weight', 'output.out_forces.2.0.weight', 'output.out_forces.2.0.bias', 'output.out_forces.2.2.weight', 'output.out_forces.2.2.bias', 'output.out_forces.2.4.weight', 'output.out_forces.2.4.bias', 'output.out_forces.2.6.weight', 'output.out_forces.2.6.bias', 'output.out_forces.2.8.weight', 'output.out_forces.3.0.weight', 'output.out_forces.3.0.bias', 'output.out_forces.3.2.weight', 'output.out_forces.3.2.bias', 'output.out_forces.3.4.weight', 'output.out_forces.3.4.bias', 'output.out_forces.3.6.weight', 'output.out_forces.3.6.bias', 'output.out_forces.3.8.weight', 'task_steps._module_dict._typed_moduledict_oc20.value', 'task_steps._module_dict._typed_moduledict_oc22.value', 'task_steps._module_dict._typed_moduledict_ani1x.value', 'task_steps._module_dict._typed_moduledict_transition1x.value']\n",
      "CRITICAL:nshtrainer.loggers.wandb:Using the `wandb-core` backend for WandB.\n",
      "INFO:nshtrainer.trainer.trainer:config.trainer.auto_determine_num_nodes ignored because no SLURM or LSF detected.\n",
      "CRITICAL:nshtrainer.trainer.trainer:LightningTrainer.__init__ with kwargs={'deterministic': None, 'fast_dev_run': True, 'max_epochs': None, 'min_epochs': None, 'max_steps': -1, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'num_sanity_val_steps': None, 'log_every_n_steps': None, 'inference_mode': True, 'callbacks': [<lightning.pytorch.callbacks.lr_monitor.LearningRateMonitor object at 0x7f4a46ab4990>, <nshtrainer.callbacks.log_epoch.LogEpochCallback object at 0x7f4a46ab3b10>, <nshtrainer.loggers.wandb.FinishWandbOnTeardownCallback object at 0x7f4a45501710>, <nshtrainer.callbacks.wandb_watch.WandbWatchCallback object at 0x7f4a45522e90>, <nshtrainer.callbacks.wandb_upload_code.WandbUploadCodeCallback object at 0x7f4a46ab20d0>, <nshtrainer._hf_hub.HFHubCallback object at 0x7f4a46ab7750>, <nshtrainer.callbacks.shared_parameters.SharedParametersCallback object at 0x7f4a45503310>, <nshtrainer.callbacks.rlp_sanity_checks.RLPSanityChecksCallback object at 0x7f4a46a99ad0>, <nshtrainer.callbacks.debug_flag.DebugFlagCallback object at 0x7f4a45503750>], 'plugins': [], 'logger': [<lightning.pytorch.loggers.wandb.WandbLogger object at 0x7f4a4635e7d0>, <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7f4a46771910>, <lightning.pytorch.loggers.csv_logs.CSVLogger object at 0x7f4a4635f5d0>], 'default_root_dir': PosixPath('/net/csefiles/coc-fung-cluster/nima/shared/repositories/jmp-backbone/configs/mptrj_alex_omat24/nshtrainer/d21m3k4d')}.\n",
      "Trainer will use only 1 of 8 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=8)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n",
      "CRITICAL:nshtrainer.trainer.trainer:LightningTrainer log directory: None.\n",
      "WARNING:nshtrainer._checkpoint.loader:No checkpoint candidates found for `last` checkpoint strategy.\n",
      "INFO:nshtrainer.trainer.checkpoint_connector:No checkpoint found for the current trainer state. Training will start from scratch.\n",
      "INFO:nshtrainer.trainer.checkpoint_connector:Loading checkpoint from: None\n",
      "You are using a CUDA device ('NVIDIA A40') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eedc03d075b466ab0e2dac2ffcbc327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/212 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "708ba39ff6e5448993b071076e69b151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/212 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:nshtrainer.callbacks.wandb_upload_code:Wandb logger not found. Skipping code upload.\n",
      "CRITICAL:nshtrainer.callbacks.debug_flag:Fast dev run detected, setting debug flag to True.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "941e287bff0442e8bfa50755f81fb64b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/212 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type              | Params | Mode \n",
      "------------------------------------------------------------\n",
      "0 | backbone      | GemNetOCBackbone  | 38.9 M | train\n",
      "1 | energy_head   | EnergyOutputHead  | 263 K  | train\n",
      "2 | force_head    | ForceOutputHead   | 1.1 M  | train\n",
      "3 | stress_head   | StressOutputHead  | 2.1 M  | train\n",
      "4 | train_metrics | ForceFieldMetrics | 0      | train\n",
      "5 | val_metrics   | ForceFieldMetrics | 0      | train\n",
      "6 | test_metrics  | ForceFieldMetrics | 0      | train\n",
      "------------------------------------------------------------\n",
      "42.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "42.3 M    Total params\n",
      "169.161   Total estimated model params size (MB)\n",
      "INFO:nshtrainer.trainer.signal_connector:No auto-requeue signals found. Reverting to default Lightning behavior.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d64a3f6b03449e585acc2063c2f2aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/212 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f94ad2e3099a45c99fb607273f3d55ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'GlobalStorage' object has no attribute 'main_edge_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m configs \u001b[38;5;241m=\u001b[39m [(config\u001b[38;5;241m.\u001b[39mfast_dev_run(), data_config)]\n\u001b[1;32m      5\u001b[0m runner \u001b[38;5;241m=\u001b[39m nr\u001b[38;5;241m.\u001b[39mRunner(run, nr\u001b[38;5;241m.\u001b[39mRunnerConfig(working_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, env\u001b[38;5;241m=\u001b[39menv))\n\u001b[0;32m----> 6\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/nshrunner/_runner.py:217\u001b[0m, in \u001b[0;36mRunner.local\u001b[0;34m(self, runs, env)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlocal\u001b[39m(\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    213\u001b[0m     runs: Iterable[\u001b[38;5;28mtuple\u001b[39m[Unpack[TArguments]]],\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m    215\u001b[0m     env: Mapping[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    216\u001b[0m ):\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/nshrunner/_runner.py:209\u001b[0m, in \u001b[0;36mRunner.local_generator\u001b[0;34m(self, runs, env)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _with_env(session\u001b[38;5;241m.\u001b[39menv):\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m _tqdm_if_installed(runs):\n\u001b[0;32m--> 209\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped_run_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/nshrunner/_runner.py:101\u001b[0m, in \u001b[0;36m_wrap_run_fn.<locals>.wrapped_run_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mseed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     99\u001b[0m     seed_everything(config\u001b[38;5;241m.\u001b[39mseed)\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(config, data_config)\u001b[0m\n\u001b[1;32m      7\u001b[0m datamodule \u001b[38;5;241m=\u001b[39m MPTrjAlexOMAT24DataModule(data_config)\n\u001b[1;32m      8\u001b[0m trainer \u001b[38;5;241m=\u001b[39m nt\u001b[38;5;241m.\u001b[39mTrainer(config)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:543\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 543\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:579\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    573\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    575\u001b[0m     ckpt_path,\n\u001b[1;32m    576\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    577\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m )\n\u001b[0;32m--> 579\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/nshtrainer/trainer/trainer.py:384\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model\u001b[38;5;241m.\u001b[39mautomatic_optimization \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_clip_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_clip_algorithm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    377\u001b[0m ):\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    379\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutomatic gradient clipping is not supported with manual optimization. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease set \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.automatic_optimization to True \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    381\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor disable automatic gradient clipping. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    382\u001b[0m     )\n\u001b[0;32m--> 384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:986\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 986\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    991\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:1030\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1029\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1030\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1031\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:205\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:363\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py:140\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py:250\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[1;32m    249\u001b[0m         \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[0;32m--> 250\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    252\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanual_optimization\u001b[38;5;241m.\u001b[39mrun(kwargs)\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py:190\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m         closure()\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py:268\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_ready()\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_completed()\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:159\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m hook_name\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 159\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    162\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/lightning/pytorch/core/module.py:1308\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimizer_step\u001b[39m(\n\u001b[1;32m   1278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1279\u001b[0m     epoch: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1282\u001b[0m     optimizer_closure: Optional[Callable[[], Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1283\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1284\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~lightning.pytorch.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;124;03m    the optimizer.\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1306\u001b[0m \n\u001b[1;32m   1307\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1308\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py:153\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py:238\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[0;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py:122\u001b[0m, in \u001b[0;36mPrecision.optimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[39;00m\n\u001b[1;32m    121\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:75\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     74\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/torch/optim/adamw.py:164\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 164\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m    167\u001b[0m     params_with_grad \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py:108\u001b[0m, in \u001b[0;36mPrecision._wrap_closure\u001b[0;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_closure\u001b[39m(\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     97\u001b[0m     model: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     98\u001b[0m     optimizer: Optimizer,\n\u001b[1;32m     99\u001b[0m     closure: Callable[[], Any],\n\u001b[1;32m    100\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    101\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    hook is called.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    106\u001b[0m \n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m     closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_closure(model, optimizer)\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m closure_result\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py:144\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py:129\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39menable_grad()\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ClosureResult:\n\u001b[0;32m--> 129\u001b[0m     step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarning_cache\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py:317\u001b[0m, in \u001b[0;36m_AutomaticOptimization._training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Performs the actual train step with the tied hooks.\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \n\u001b[1;32m    308\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    313\u001b[0m \n\u001b[1;32m    314\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    315\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\n\u001b[0;32m--> 317\u001b[0m training_step_output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mpost_training_step()  \u001b[38;5;66;03m# unused hook - call anyway for backward compatibility\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training_step_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mworld_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:311\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 311\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    314\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py:390\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 390\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/shared/repositories/jmp-backbone/src/jmp/lightning_module.py:169\u001b[0m, in \u001b[0;36mModule.training_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtraining_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch: Batch, batch_idx: \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_context(prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 169\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_common_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_metrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/shared/repositories/jmp-backbone/src/jmp/lightning_module.py:154\u001b[0m, in \u001b[0;36mModule._common_step\u001b[0;34m(self, data, metrics)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_common_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: Batch, metrics: ForceFieldMetrics):\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m cast(Predictions, outputs)\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/shared/repositories/jmp-backbone/src/jmp/lightning_module.py:103\u001b[0m, in \u001b[0;36mModule.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: Batch):\n\u001b[0;32m--> 103\u001b[0m     backbone_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     output_head_input \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackbone_output\u001b[39m\u001b[38;5;124m\"\u001b[39m: backbone_output, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data}\n\u001b[1;32m    106\u001b[0m     outputs: Predictions \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menergy\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menergy_head(output_head_input),\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforces\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforce_head(output_head_input),\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstress\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstress_head(output_head_input),\n\u001b[1;32m    110\u001b[0m     }\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/shared/repositories/jmp-backbone/src/jmp/models/gemnet/backbone.py:684\u001b[0m, in \u001b[0;36mGemNetOCBackbone.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    670\u001b[0m     pos\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    672\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(atomic_numbers \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    674\u001b[0m (\n\u001b[1;32m    675\u001b[0m     main_graph,\n\u001b[1;32m    676\u001b[0m     a2a_graph,\n\u001b[1;32m    677\u001b[0m     a2ee2a_graph,\n\u001b[1;32m    678\u001b[0m     qint_graph,\n\u001b[1;32m    679\u001b[0m     id_swap,\n\u001b[1;32m    680\u001b[0m     trip_idx_e2e,\n\u001b[1;32m    681\u001b[0m     trip_idx_a2e,\n\u001b[1;32m    682\u001b[0m     trip_idx_e2a,\n\u001b[1;32m    683\u001b[0m     quad_idx,\n\u001b[0;32m--> 684\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_graphs_and_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    685\u001b[0m idx_s, idx_t \u001b[38;5;241m=\u001b[39m main_graph[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    687\u001b[0m bases: BasesOutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbases(\n\u001b[1;32m    688\u001b[0m     data,\n\u001b[1;32m    689\u001b[0m     h\u001b[38;5;241m=\u001b[39mh,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    698\u001b[0m     num_atoms\u001b[38;5;241m=\u001b[39mnum_atoms,\n\u001b[1;32m    699\u001b[0m )\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/shared/repositories/jmp-backbone/src/jmp/models/gemnet/backbone.py:594\u001b[0m, in \u001b[0;36mGemNetOCBackbone.get_graphs_and_indices\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    586\u001b[0m num_atoms \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39matomic_numbers\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matom_edge_interaction\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_atom_interaction\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matom_interaction\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquad_interaction\n\u001b[1;32m    592\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly the full interaction graph (ae + ea + a + q) is supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 594\u001b[0m graphs \u001b[38;5;241m=\u001b[39m \u001b[43mgraphs_from_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    595\u001b[0m a2a_graph \u001b[38;5;241m=\u001b[39m graphs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma2a\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    596\u001b[0m a2ee2a_graph \u001b[38;5;241m=\u001b[39m graphs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma2ee2a\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/shared/repositories/jmp-backbone/src/jmp/models/gemnet/graph.py:526\u001b[0m, in \u001b[0;36mgraphs_from_batch\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgraphs_from_batch\u001b[39m(data: BaseData \u001b[38;5;241m|\u001b[39m Batch) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Graphs:\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;28;01mglobal\u001b[39;00m GRAPH_TYPES\n\u001b[0;32m--> 526\u001b[0m     graphs \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgraph_type\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43medge_index\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mgraph_type\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_edge_index\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdistance\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mgraph_type\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_distance\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvector\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mgraph_type\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_vector\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcell_offset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mgraph_type\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_cell_offset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_neighbors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mgraph_type\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_num_neighbors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcutoff\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mgraph_type\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_cutoff\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_neighbors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mgraph_type\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_max_neighbors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid_swap_edge_index\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mgraph_type\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_id_swap_edge_index\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    537\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mGRAPH_TYPES\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;66;03m# remove None values\u001b[39;00m\n\u001b[1;32m    542\u001b[0m     graphs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    543\u001b[0m         graph_type: {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[1;32m    544\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m graph_type, graph \u001b[38;5;129;01min\u001b[39;00m graphs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    545\u001b[0m     }\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/shared/repositories/jmp-backbone/src/jmp/models/gemnet/graph.py:528\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgraphs_from_batch\u001b[39m(data: BaseData \u001b[38;5;241m|\u001b[39m Batch) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Graphs:\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;28;01mglobal\u001b[39;00m GRAPH_TYPES\n\u001b[1;32m    526\u001b[0m     graphs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    527\u001b[0m         graph_type: {\n\u001b[0;32m--> 528\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mgraph_type\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_edge_index\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    529\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mgetattr\u001b[39m(data, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgraph_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_distance\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    530\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvector\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mgetattr\u001b[39m(data, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgraph_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_vector\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    531\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_offset\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mgetattr\u001b[39m(data, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgraph_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_cell_offset\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    532\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_neighbors\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mgetattr\u001b[39m(data, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgraph_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_num_neighbors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    533\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcutoff\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mgetattr\u001b[39m(data, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgraph_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_cutoff\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    534\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_neighbors\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mgetattr\u001b[39m(data, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgraph_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_max_neighbors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    535\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid_swap_edge_index\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[1;32m    536\u001b[0m                 data, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgraph_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_id_swap_edge_index\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    537\u001b[0m             ),\n\u001b[1;32m    538\u001b[0m         }\n\u001b[1;32m    539\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m graph_type \u001b[38;5;129;01min\u001b[39;00m GRAPH_TYPES\n\u001b[1;32m    540\u001b[0m     }\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;66;03m# remove None values\u001b[39;00m\n\u001b[1;32m    542\u001b[0m     graphs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    543\u001b[0m         graph_type: {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[1;32m    544\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m graph_type, graph \u001b[38;5;129;01min\u001b[39;00m graphs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    545\u001b[0m     }\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/torch_geometric/data/data.py:559\u001b[0m, in \u001b[0;36mData.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_store\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    555\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object was created by an older version of PyG. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    556\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf this error occurred while loading an already existing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    557\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset, remove the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m directory in the dataset\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    558\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot folder and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_store\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/torch_geometric/data/storage.py:96\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GlobalStorage' object has no attribute 'main_edge_index'"
     ]
    }
   ],
   "source": [
    "import nshrunner as nr\n",
    "\n",
    "configs = [(config.fast_dev_run(), data_config)]\n",
    "\n",
    "runner = nr.Runner(run, nr.RunnerConfig(working_dir=\".\", env=env))\n",
    "runner.local(configs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jmp-peft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
